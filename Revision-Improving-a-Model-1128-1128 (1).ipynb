{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will improve the logistic regression model we built in the previous tutorial. The techniques we will use to improve the model are:\n",
    "1. Using a subset of the features\n",
    "2. Tuning the model parameter C\n",
    "\n",
    "The measures for improvement will be based on precision, recall and f1-score - all which can be extracted from the classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a subset of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same teachnique we used in the linear regression sprint when we compared various models. It can potentially lead to better results for the testing data if some features in the model are redundant. We will build three different models:\n",
    "* Full model (all features)\n",
    "* Basic info model (age, sex, region)\n",
    "* Lifestyle model (steps, BMI, children, smoking status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries we will need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>steps</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>insurance_claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>3009</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>3008</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3009</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>10009</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>8010</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  steps  children smoker     region insurance_claim\n",
       "0   19  female  27.900   3009         0    yes  southwest             yes\n",
       "1   18    male  33.770   3008         1     no  southeast             yes\n",
       "2   28    male  33.000   3009         3     no  southeast              no\n",
       "3   33    male  22.705  10009         0     no  northwest              no\n",
       "4   32    male  28.880   8010         0     no  northwest             yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read claims data in and view first few entries\n",
    "df = pd.read_csv('claims_data-a-1128 (1).csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the following pre-processing steps will be performed, for each of the three models:\n",
    "* Splitting the data into features and labels\n",
    "* Transforming the features \n",
    "* Splitting the data into training and testing data\n",
    "\n",
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['insurance_claim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_full = df.drop('insurance_claim', axis=1)\n",
    "\n",
    "# Transforming the Features\n",
    "X_full_transformed = pd.get_dummies(X_full, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X_full_transformed, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Info Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_info = df[['age','sex','region']]\n",
    "\n",
    "# Transforming the Features\n",
    "X_info_transformed = pd.get_dummies(X_info, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "X_train_info, X_test_info, y_train, y_test = train_test_split(X_info_transformed, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lifestyle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_life = df[['bmi','steps','children','smoker']]\n",
    "\n",
    "# Transforming the Features\n",
    "X_life_transformed = pd.get_dummies(X_life, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "X_train_life, X_test_life, y_train, y_test = train_test_split(X_life_transformed, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready. Let's train the logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create instances for the `LogisticRegression()` object. Then we fit the models using the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = LogisticRegression()\n",
    "info = LogisticRegression()\n",
    "life = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.fit(X_train_full,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.fit(X_train_info, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life.fit(X_train_life, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make predictions usig the `predict()` method that we want to ultimately compare with the actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_full = full.predict(X_test_full)\n",
    "pred_info = info.predict(X_test_info)\n",
    "pred_life = life.predict(X_test_life)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing the results we will look at precision, recall and f1-score in the **classification report**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   No claim       0.85      0.84      0.84       116\n",
      "      Claim       0.88      0.89      0.88       152\n",
      "\n",
      "avg / total       0.87      0.87      0.87       268\n",
      "\n",
      "Info Model\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   No claim       0.46      0.20      0.28       116\n",
      "      Claim       0.57      0.82      0.68       152\n",
      "\n",
      "avg / total       0.52      0.55      0.50       268\n",
      "\n",
      "Lifestyle Model\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   No claim       0.88      0.84      0.86       116\n",
      "      Claim       0.88      0.91      0.90       152\n",
      "\n",
      "avg / total       0.88      0.88      0.88       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Full Model')\n",
    "print(classification_report(y_test, pred_full, target_names=['No claim', 'Claim']))\n",
    "\n",
    "print('Info Model')\n",
    "print(classification_report(y_test, pred_info, target_names=['No claim', 'Claim']))\n",
    "\n",
    "print('Lifestyle Model')\n",
    "print(classification_report(y_test, pred_life, target_names=['No claim', 'Claim']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the lifestyle model produced better results compared to the full model. This implies that some of the basic information might be redundant since adding it leads to worse results. \n",
    "\n",
    "The info model by itself also produced poor results - guessing should in theory produce similar results (i.e. 50%)\n",
    "\n",
    "See if you can find a subset of the features that will outperform the lifestyle model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the model parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models have tuning parameters that can be changed to alter the fit of the model. \n",
    "\n",
    "For the logistic regression model we have a parameter **C** which is used to control the penalty we apply to features that are less important (i.e. more important features will have greater weight). The smaller the value of **C**, the greater the penalty to less important features. **C** is a value greater than 0.\n",
    "\n",
    "Let's build three models (on all the features) with different values of **C** and see how they compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create instances of the `LogisticRegression()` object, specifying the value of the parameter C. Then we fit the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C=0.1\n",
    "model_1 = LogisticRegression(C=0.1)\n",
    "\n",
    "# C=1 (same as original)\n",
    "model_2 = LogisticRegression(C=1)\n",
    "\n",
    "# C=10\n",
    "model_3 = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train_full,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(X_train_full,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train_full,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models have been trained. Let's make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = model_1.predict(X_test_full)\n",
    "pred_2 = model_2.predict(X_test_full)\n",
    "pred_3 = model_3.predict(X_test_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will once again use the classification report to compare the model results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   No claim       0.84      0.78      0.81       116\n",
      "      Claim       0.84      0.89      0.87       152\n",
      "\n",
      "avg / total       0.84      0.84      0.84       268\n",
      "\n",
      "C = 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   No claim       0.85      0.84      0.84       116\n",
      "      Claim       0.88      0.89      0.88       152\n",
      "\n",
      "avg / total       0.87      0.87      0.87       268\n",
      "\n",
      "C = 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   No claim       0.85      0.84      0.84       116\n",
      "      Claim       0.88      0.89      0.88       152\n",
      "\n",
      "avg / total       0.87      0.87      0.87       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('C = 0.1')\n",
    "print(classification_report(y_test, pred_1, target_names=['No claim', 'Claim']))\n",
    "\n",
    "print('C = 1')\n",
    "print(classification_report(y_test, pred_2, target_names=['No claim', 'Claim']))\n",
    "\n",
    "print('C = 10')\n",
    "print(classification_report(y_test, pred_3, target_names=['No claim', 'Claim']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like C values of 1 and 10 gave the best results. See if you can find a value of C that leads to even better results. And if you are up for the challenge, see if you can combine using a subset of the data and tuning C to find the optimal logistic regression model for this problem!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
